{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc91607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672d6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check scikit-learn version\n",
    "# import sklearn\n",
    "# print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f23e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df=pd.read_csv(r'part_1_customerServiceTwitterHandle.csv',sep=',', header=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a2bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['message'], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67fa6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4159ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.DataFrame()\n",
    "customer['message'] = df['message'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ce7f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@1800flowershelp It's Mrs Wright and I no long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@1800flowershelp I did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@1800flowershelp It's cool. Still crickets fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@1800flowershelp Thanks, Alex. I was fine unti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@1800flowershelp I ordered flowers for a colle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@1800flowershelp Dm sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@1800flowershelp your service is terrible. I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@1800flowershelp ðð¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@1800flowershelp DM sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>goo.gl/images/KobUwp This is how I feel @1800f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@1800flowershelp @JCWright13 How about you rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@1800flowershelp I did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@1800flowershelp Iâm currently chatting with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@1800flowershelp Thank you for your fast reply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@1800flowershelp Ok I should be upset because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@1800flowershelp I have spoken to customer ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@1800flowershelp You cannot assist me, you wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@1800flowershelp I am sorry, yesterday was a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@1800flowershelp I've already been through it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@1800flowershelp Just dm'd @1800flowershelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message\n",
       "0   @1800flowershelp It's Mrs Wright and I no long...\n",
       "1                              @1800flowershelp I did\n",
       "2   @1800flowershelp It's cool. Still crickets fro...\n",
       "3   @1800flowershelp Thanks, Alex. I was fine unti...\n",
       "4   @1800flowershelp I ordered flowers for a colle...\n",
       "5                            @1800flowershelp Dm sent\n",
       "6   @1800flowershelp your service is terrible. I w...\n",
       "7                           @1800flowershelp ðð¾\n",
       "8                            @1800flowershelp DM sent\n",
       "9   goo.gl/images/KobUwp This is how I feel @1800f...\n",
       "10  @1800flowershelp @JCWright13 How about you rep...\n",
       "11                             @1800flowershelp I did\n",
       "12  @1800flowershelp Iâm currently chatting with...\n",
       "13  @1800flowershelp Thank you for your fast reply...\n",
       "14  @1800flowershelp Ok I should be upset because ...\n",
       "15  @1800flowershelp I have spoken to customer ser...\n",
       "16  @1800flowershelp You cannot assist me, you wer...\n",
       "17  @1800flowershelp I am sorry, yesterday was a b...\n",
       "18  @1800flowershelp I've already been through it ...\n",
       "19        @1800flowershelp Just dm'd @1800flowershelp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22854902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06355ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb644cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_processed = pd.DataFrame(columns = ['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23b0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "for string in customer['message']:\n",
    "    res = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|[^\\w\\s])\\S+\", \"\", string)\n",
    "    res = re.sub(r\"[^\\w\\s]\", \"\", res)\n",
    "    res = re.sub(r'[0-9]+', '', res)\n",
    "    res = re.sub(r'[?|$|_|.|!]+',r'', res)\n",
    "    res = re.sub(r'\\b\\w{1,2}\\b', \"\", res)\n",
    "    tokens = nltk.word_tokenize(res)\n",
    "    if len(tokens)<=3: continue;\n",
    "    res = \" \".join(tokens)\n",
    "    customer_processed = customer_processed._append({'message': res}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2821082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25644, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e44127a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46210</th>\n",
       "      <td>RT @zumiez @mares182 Hit up @zumiezhelp and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46211</th>\n",
       "      <td>@zumiez @zumiezhelp Can y'all get a message to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46212</th>\n",
       "      <td>Need help or have questions about your order? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46213</th>\n",
       "      <td>@zumiezhelp DM sent. Thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46214</th>\n",
       "      <td>@zumiezhelp I was told to DM u so can u follow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message\n",
       "46210  RT @zumiez @mares182 Hit up @zumiezhelp and th...\n",
       "46211  @zumiez @zumiezhelp Can y'all get a message to...\n",
       "46212  Need help or have questions about your order? ...\n",
       "46213                        @zumiezhelp DM sent. Thanks\n",
       "46214  @zumiezhelp I was told to DM u so can u follow..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c03dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(r'Non customer tweets.csv',sep=',', header=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85713d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(subset = ['message'], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c78bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_customer = pd.DataFrame()\n",
    "non_customer['message'] = df1['message'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca600d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I j_u_st ____ entered QVC & HSN's Black Friday...\n",
       "1       AutoNation $AN PT Lowered to $38.00 at Bucking...\n",
       "2       Le Chat Noir Thanksgiving Pilgrim available at...\n",
       "3       Sysco AS,  acquired Basecare #acquisition  #mn...\n",
       "4       Happy Halloween from the PETTY-est person I kn...\n",
       "                              ...                        \n",
       "3144    Gymboree Almost Everything $19.99 and Under. C...\n",
       "3145    Mason thinks he was born from the land down un...\n",
       "3146    Thanks to all the pastors and church leaders i...\n",
       "3147    Clouds alpha Key> shutterstock.com/video/clip-...\n",
       "3148                    Supporting our #BCreative Sponsor\n",
       "Name: message, Length: 3146, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_customer['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5976084",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_customer_processed = pd.DataFrame(columns = ['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f42a0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in non_customer['message']:\n",
    "    res = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|[^\\w\\s])\\S+\", \"\", string)\n",
    "    res = re.sub(r\"[^\\w\\s]\", \"\", res)\n",
    "    res = re.sub(r'[0-9]+', '', res)\n",
    "    res = re.sub(r'[?|$|_|.|!]+',r'', res)\n",
    "    res = re.sub(r'\\b\\w{1,2}\\b', \"\", res)\n",
    "    tokens = nltk.word_tokenize(res)\n",
    "    if len(tokens)<=3: continue;\n",
    "    res = \" \".join(tokens)\n",
    "    non_customer_processed = non_customer_processed._append({'message': res}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82778a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2848, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_customer_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c99c28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I j_u_st ____ entered QVC &amp; HSN's Black Friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoNation $AN PT Lowered to $38.00 at Bucking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le Chat Noir Thanksgiving Pilgrim available at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sysco AS,  acquired Basecare #acquisition  #mn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy Halloween from the PETTY-est person I kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Top 10 Winn Dixie Sales with Coupon Matchups F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tech students ranking items needed for survivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AutoNation $AN Price Target Cut to $38.00 amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautiful day yesterday. #flyfishing was lousy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Save the Date! Our 1st #TaylormillerHSD #Wareh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  I j_u_st ____ entered QVC & HSN's Black Friday...\n",
       "1  AutoNation $AN PT Lowered to $38.00 at Bucking...\n",
       "2  Le Chat Noir Thanksgiving Pilgrim available at...\n",
       "3  Sysco AS,  acquired Basecare #acquisition  #mn...\n",
       "4  Happy Halloween from the PETTY-est person I kn...\n",
       "5  Top 10 Winn Dixie Sales with Coupon Matchups F...\n",
       "6  Tech students ranking items needed for survivi...\n",
       "7  AutoNation $AN Price Target Cut to $38.00 amer...\n",
       "8  Beautiful day yesterday. #flyfishing was lousy...\n",
       "9  Save the Date! Our 1st #TaylormillerHSD #Wareh..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_customer.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d036696",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_processed['flag'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bc30709",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_customer_processed['flag'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7be27058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2848, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_customer_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db0077c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = customer_processed[:3152].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cced481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data._append(non_customer_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "606b13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('data.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90f6e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Ticket Data\n",
    "corpus = data['message'].values\n",
    " \n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    " \n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "# print(vectorizer.get_feature_names())\n",
    " \n",
    "# Preparing Data frame For machine learning\n",
    "# flag column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=None)\n",
    "# CountVectorizedData.flags.allows_duplicate_labels = False\n",
    "CountVectorizedData.index = data['message'].index\n",
    "CountVectorizedData['flag'] = data['flag']\n",
    "# print(CountVectorizedData['flag'])\n",
    "# print(CountVectorizedData.shape)\n",
    "# CountVectorizedData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6718de1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NISHAN~1\\AppData\\Local\\Temp/ipykernel_20960/3813778585.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#Loading the word vectors from Google trained word2Vec model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mGoogleModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "#Loading the word vectors from Google trained word2Vec model\n",
    "GoogleModel = gensim.models.KeyedVectors.load_word2vec_format(r'GoogleNews-vectors-negative300.bin', binary=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76c97bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each word is a vector of 300 numbers\n",
    "GoogleModel['hello'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "713aa413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aaallll', 'aaron', 'aaxa', 'abandoned', 'abandonment', 'abbey', 'abc',\n",
       "       'abcactionnews', 'abcn', 'abercrombie'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the list of words which are present in the Document term matrix\n",
    "WordsVocab=CountVectorizedData.columns[1:-1]\n",
    "\n",
    "# Printing sample words\n",
    "WordsVocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50b459b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which takes text input and returns one vector for each sentence\n",
    "def FunctionText2Vec(inpTextData):\n",
    "    # Converting the text to numeric data\n",
    "    X = vectorizer.transform(inpTextData)\n",
    "    CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "    W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "    # Looping through each row for the data\n",
    "    for i in range(CountVecData.shape[0]):\n",
    "\n",
    "        # initiating a sentence with all zeros\n",
    "        Sentence = np.zeros(300)\n",
    "\n",
    "        # Looping thru each word in the sentence and if its present in \n",
    "        # the Word2Vec model then storing its vector\n",
    "        for word in WordsVocab[CountVecData.iloc[i,:]]:\n",
    "            #print(word)\n",
    "            if word in GoogleModel.key_to_index.keys():    \n",
    "                Sentence=Sentence+GoogleModel[word]\n",
    "        # Appending the sentence to the dataframe\n",
    "        W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence]))\n",
    "    return(W2Vec_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5a0a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shobh\\anaconda3\\envs\\Project\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6000, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the function to convert all the text data to Word2Vec Vectors\n",
    "W2Vec_Data=FunctionText2Vec(data['message'])\n",
    "\n",
    "# Checking the new representation for sentences\n",
    "W2Vec_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20203813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008362</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>1.468750</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>-1.093750</td>\n",
       "      <td>-1.476562</td>\n",
       "      <td>-0.886719</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>-0.085449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>2.406250</td>\n",
       "      <td>-0.914062</td>\n",
       "      <td>-2.75000</td>\n",
       "      <td>-0.667969</td>\n",
       "      <td>-1.398438</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>1.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004181</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.546875</td>\n",
       "      <td>-0.738281</td>\n",
       "      <td>-0.443359</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>-0.042725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>1.203125</td>\n",
       "      <td>-0.457031</td>\n",
       "      <td>-1.37500</td>\n",
       "      <td>-0.333984</td>\n",
       "      <td>-0.699219</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018814</td>\n",
       "      <td>2.302734</td>\n",
       "      <td>1.766602</td>\n",
       "      <td>3.304688</td>\n",
       "      <td>0.221924</td>\n",
       "      <td>-2.460938</td>\n",
       "      <td>-3.322266</td>\n",
       "      <td>-1.995117</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>-0.192261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>2.373047</td>\n",
       "      <td>5.414062</td>\n",
       "      <td>-2.056641</td>\n",
       "      <td>-6.18750</td>\n",
       "      <td>-1.502930</td>\n",
       "      <td>-3.146484</td>\n",
       "      <td>2.373047</td>\n",
       "      <td>3.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015678</td>\n",
       "      <td>1.918945</td>\n",
       "      <td>1.472168</td>\n",
       "      <td>2.753906</td>\n",
       "      <td>0.184937</td>\n",
       "      <td>-2.050781</td>\n",
       "      <td>-2.768555</td>\n",
       "      <td>-1.662598</td>\n",
       "      <td>1.047363</td>\n",
       "      <td>-0.160217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053101</td>\n",
       "      <td>1.245117</td>\n",
       "      <td>1.977539</td>\n",
       "      <td>4.511719</td>\n",
       "      <td>-1.713867</td>\n",
       "      <td>-5.15625</td>\n",
       "      <td>-1.252441</td>\n",
       "      <td>-2.622070</td>\n",
       "      <td>1.977539</td>\n",
       "      <td>2.724609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005226</td>\n",
       "      <td>0.639648</td>\n",
       "      <td>0.490723</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>-0.683594</td>\n",
       "      <td>-0.922852</td>\n",
       "      <td>-0.554199</td>\n",
       "      <td>0.349121</td>\n",
       "      <td>-0.053406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.415039</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>1.503906</td>\n",
       "      <td>-0.571289</td>\n",
       "      <td>-1.71875</td>\n",
       "      <td>-0.417480</td>\n",
       "      <td>-0.874023</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.908203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.008362  1.023438  0.785156  1.468750  0.098633 -1.093750 -1.476562   \n",
       "0 -0.004181  0.511719  0.392578  0.734375  0.049316 -0.546875 -0.738281   \n",
       "0 -0.018814  2.302734  1.766602  3.304688  0.221924 -2.460938 -3.322266   \n",
       "0 -0.015678  1.918945  1.472168  2.753906  0.184937 -2.050781 -2.768555   \n",
       "0 -0.005226  0.639648  0.490723  0.917969  0.061646 -0.683594 -0.922852   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.886719  0.558594 -0.085449  ...  0.028320  0.664062  1.054688  2.406250   \n",
       "0 -0.443359  0.279297 -0.042725  ...  0.014160  0.332031  0.527344  1.203125   \n",
       "0 -1.995117  1.256836 -0.192261  ...  0.063721  1.494141  2.373047  5.414062   \n",
       "0 -1.662598  1.047363 -0.160217  ...  0.053101  1.245117  1.977539  4.511719   \n",
       "0 -0.554199  0.349121 -0.053406  ...  0.017700  0.415039  0.659180  1.503906   \n",
       "\n",
       "        294      295       296       297       298       299  \n",
       "0 -0.914062 -2.75000 -0.667969 -1.398438  1.054688  1.453125  \n",
       "0 -0.457031 -1.37500 -0.333984 -0.699219  0.527344  0.726562  \n",
       "0 -2.056641 -6.18750 -1.502930 -3.146484  2.373047  3.269531  \n",
       "0 -1.713867 -5.15625 -1.252441 -2.622070  1.977539  2.724609  \n",
       "0 -0.571289 -1.71875 -0.417480 -0.874023  0.659180  0.908203  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vec_Data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4525edf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 10291)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the above with the document term matrix\n",
    "CountVectorizedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a2a011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the target variable\n",
    "W2Vec_Data.reset_index(inplace=True, drop=True)\n",
    "W2Vec_Data.index=CountVectorizedData.index\n",
    "W2Vec_Data['flag']=CountVectorizedData['flag']\n",
    "\n",
    "# Assigning to DataForML variable\n",
    "DataForML=W2Vec_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "624aaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit(DataForML[DataForML.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30f41a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(DataForML, shuffle = True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee6ab2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame()\n",
    "train_y = pd.DataFrame()\n",
    "test_x = pd.DataFrame()\n",
    "test_y = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c5fcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[train.columns[:-1]].values\n",
    "train_y = train[train.columns[-1]].values\n",
    "test_x= test[test.columns[:-1]].values\n",
    "test_y = test[test.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3d26e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199 363]\n",
      " [177 461]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.35      0.42       562\n",
      "           1       0.56      0.72      0.63       638\n",
      "\n",
      "    accuracy                           0.55      1200\n",
      "   macro avg       0.54      0.54      0.53      1200\n",
      "weighted avg       0.55      0.55      0.53      1200\n",
      "\n",
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "classifier = LogisticRegression(C=10,penalty='l2', solver='newton-cg')\n",
    "# classifier = KNeighborsClassifier(n_neighbors=15)\n",
    "# classifier = tree.DecisionTreeClassifier(max_depth=20,criterion='gini')\n",
    "classifier.fit(train_x, train_y)\n",
    "pred = classifier.predict(test_x)\n",
    "# print(pred.shape)\n",
    "\n",
    "# pred = pd.DataFrame(pred, columns=['flag'])\n",
    "# pred.index = test_y.index\n",
    "# print(pred.tail(10))\n",
    "\n",
    "score = accuracy_score(test_y, pred)\n",
    "print(confusion_matrix(test_y, pred))\n",
    "print(classification_report(test_y, pred))\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5147077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> set(test_y) - set(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efdd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
